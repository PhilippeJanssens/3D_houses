{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" plotting with help \"\"\"\n",
    "# source: https://medium.com/@sukantkhurana/analyzing-geospatial-data-with-geopandas-and-plotly-b13dedcbe466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd865e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7699ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset needed\n",
    "\n",
    "\"\"\"\n",
    "Open in app\n",
    "Sukant Khurana\n",
    "673 Followers\n",
    "About\n",
    "Open in app\n",
    "\n",
    "Analyzing geospatial data with GeoPandas and plotly\n",
    "Sukant Khurana\n",
    "\n",
    "Sukant Khurana\n",
    "\n",
    "Feb 23, 2019·8 min read\n",
    "\n",
    "by Siddharth Dutta\n",
    "\n",
    "(The article is written entirely by my student Siddharth, as part of assignment to learn about geospatial data plotting in Python. I have not edited a word so all praise and criticism are his. I found this work worthy of sharing, so putting it on my blog with due credit to him)\n",
    "\n",
    "GeoPandas\n",
    "\n",
    "The goal of GeoPandas is to make working with geospatial data in python easier. It combines the capabilities of pandas and shapely, providing geospatial operations in pandas and a high-level interface to multiple geometries to shapely. GeoPandas enables you to easily do operations in python that would otherwise require a spatial database such as PostGIS.\n",
    "\n",
    "In this article we are going to study about using GeoPandas on a geospatial dataset about all the countries of the world.\n",
    "\n",
    "Before we get to the visuals, let’s talk about shape files. A .shp file is actually just one of the 3 files that are necessary for your shape data to render — you may have noticed that a .shp file comes in a zip file when you download. This is because you also need a .dbf and a .shx file. While the .shp files gives figures their geometry, .dbf stores attribute data and object ids, and .shx provides an index that is helpful with certain software and packages (such as pyshp and AutoCAD).\n",
    "\n",
    "GeoPandas (and shapely for theindividual objects) provides a whole lot of basic methods to analyse the geospatial datan (distance,length,centroid,boundary,convex_hull,simplify,transform,..).\n",
    "\n",
    "GeoDataFrame is a data frame which has a ‘geometry’ column. The .geometry attribute returns a GeoSeries (the column name itself is not necessarily ‘geometry’).\n",
    "\n",
    "GeoSeries is a Series that holds (shapely) geometry objects (Points, LineStrings, Polygons, …).\n",
    "\n",
    "Plotly\n",
    "\n",
    "The plotly Python package is an open-source library built on plotly.js, which in turn is built on d3.js.\n",
    "\n",
    "We can create graphs which are more interactive in nature than matplotlib. It also allows us to perform better analysis and draw accurate insights from our observations.\n",
    "GIS Spatial Data Types\n",
    "There are two broad categories of geospatial data-:\n",
    "\n",
    "1.Raster data: It is made up of pixels (also referred to as grid cells). They are usually evenly spaced and square. Raster data often look pixelated because each pixel has its own value or class. E.g-: Satellite images.\n",
    "\n",
    "2.Vector data: Vector data is split into three types: polygon, line (or arc) and point data. Polygons are used to represent areas such as the boundary of a city (on a large scale map), lake, or forest. Polygon features are two dimensional and therefore can be used to measure the area and perimeter of a geographic feature. Polygon features are most commonly distinguished using either a thematic mapping symbol (color schemes), patterns, or in the case of numeric gradation, a color gradation scheme could be used.\n",
    "\n",
    "Visualization in Spatial Data Analysis\n",
    "\n",
    "Here we use our dataset to describe a common type of geo-visualization used for area unit data with numeric attributes, namely choropleth maps. Choropleth maps play a prominent role in spatial data science. The word choropleth stems from the root “choro” meaning “region”. As such choropleth maps are appropriate for areal unit data where each observation combines a value of an attribute and a polygon. Choropleth maps derive from an earlier era where cartographers faced technological constraints that precluded the use of unclassed maps where each unique attribute value could be represented by a distinct symbol. Instead, attribute values were grouped into a smaller number of classes with each class being associated with a unique symbol that was in turn applied to all polygons with attribute values falling in the class.\n",
    "\n",
    "The effectiveness of a choropleth map will be a function of the choice of classification scheme together with the color or symbolization strategy adopted. In broad terms, the classification scheme defines the number of classes as well as the rules for assignment, while the symbolization should convey information about the value differentiation across the classes.\n",
    "\n",
    "Lets Load our dataset:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "df = gpd.read_file('data/berlin-districts.geojson')import seaborn as sbn\n",
    "\n",
    "We can use seaborn to visualize the statistical distribution of the median price of listings across districts:\n",
    "\n",
    "sbn.distplot(df['median_price'])\n",
    "\n",
    "The distplot combines a histogram with a kernel density. Both reflect a right-skewed distribution, not uncommon for housing rents, or urban income distributions.\n",
    "\n",
    "sbn.distplot(df['median_price'], rug=True)\n",
    "\n",
    "Adding the rug argument provides additional insight as to the distribution of specific observations across the price range. The histogram and density give us a sense of the \"value\" distribution. From a spatial data science perspective, we are also interested in the \"spatial\" distribution of these values.\n",
    "\n",
    "Since we have a GeoDataFrame we can call the plot method to generate a default choropleth:\n",
    "\n",
    "Alternatively, we can plot a choropleth map using plotly by following the given instructions-:\n",
    "\n",
    "(NOTE-: The data comprises of information about public Education spending of various states of america)\n",
    "\n",
    "import plotly.offline as plt\n",
    "\n",
    "df=pd.read_csv(‘states.csv’)\n",
    "\n",
    "data=[dict(type=’choropleth’, autocolorscale = False,\n",
    "\n",
    "locations=df[‘code’], z=df[‘dollars’], locationmode=’USA-states’, colorscale=’custom-colorscale’, colorbar=dict(title=’thousand dollars’))]\n",
    "\n",
    "layout = dict(title=’state spending on public education’, geo=dict(scope=’usa’, projection=dict(type=’albers usa’), showlakes=True, lakecolor=’rgb(66,165,245)’))\n",
    "\n",
    "fig=dict(data=data, layout=layout)\n",
    "\n",
    "plt.plot(fig)\n",
    "Kernel Regressions\n",
    "\n",
    "Kernel regressions are one exceptionally common way to allow observations to “borrow strength” from nearby observations.\n",
    "\n",
    "However, when working with spatial data, there are two simultaneous senses of what is near:\n",
    "\n",
    "· Things that are similar in attribute (classical kernel regression)\n",
    "\n",
    "· Things that are similar in spatial position (spatial kernel regression)\n",
    "\n",
    "Below, we’ll walk through how to use scikit to fit these two types of kernel regressions, show how it’s not super simple to mix the two approaches together, and refer to an approach that does this correctly in another package.\n",
    "\n",
    "model_data = listings[[‘accommodates’,‘review_scores_rating’,’bedrooms’, ‘bathrooms’, ‘beds’,’price’, ‘geometry’]].dropna()\n",
    "\n",
    "Xnames = [‘accommodates’, ‘review_scores_rating’,’bedrooms’, ‘bathrooms’, ‘beds’]\n",
    "\n",
    "X = model_data[Xnames].values X = X.astype(float) y = np.log(model_data[[‘price’]].values)\n",
    "\n",
    "coordinates = np.vstack(model_data.geometry.apply(lambda p: np.hstack(p.xy)).values)\n",
    "\n",
    "scikit neighbor regressions are contained in the sklearn.neighbors module, and there are two main types:\n",
    "\n",
    "· KNeighborsRegressor, which uses a k-nearest neighborhood of observations around each focal site\n",
    "\n",
    "· RadiusNeighborsRegressor, which considers all observations within a fixed radius around each focal site.\n",
    "\n",
    "Further, these methods can use inverse distance weighting to rank the relative importance of sites around each focal; in this way, near things are given more weight than far things, even when there’s a lot of near things.\n",
    "\n",
    "import sklearn.neighbors as skn\n",
    "\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "shuffle = np.random.permutation(len(y))\n",
    "\n",
    "train,test =shuffle[:14000],shuffle[14000:]\n",
    "\n",
    "So, let’s fit three models:\n",
    "\n",
    "· spatial: using inverse distance weighting on the nearest 500 neighbors geograpical space\n",
    "\n",
    "· attribute: using inverse distance weighting on the nearest 500 neighbors in attribute space\n",
    "\n",
    "· both: using inverse distance weighting in both geographical and attribute space.\n",
    "\n",
    "KNNR = skn.KNeighborsRegressor(weights=’distance’, n_neighbors=500)\n",
    "\n",
    "spatial = KNNR.fit(coordinates[train,:], y[train,:])\n",
    "\n",
    "KNNR = skn.KNeighborsRegressor(weights=’distance’, n_neighbors=500)\n",
    "\n",
    "attribute = KNNR.fit(X[train,:],y[train,])\n",
    "\n",
    "KNNR = skn.KNeighborsRegressor(weights=’distance’, n_neighbors=500) both = KNNR.fit(np.hstack((coordinates,X))[train,:],y[train,:])\n",
    "\n",
    "To score them, I’m going to grab them out of sample prediction accuracy and get their % explained variance:\n",
    "\n",
    "sp_ypred =spatial.predict(coordinates[test,:])\n",
    "\n",
    "att_ypred = attribute.predict(X[test,:])\n",
    "\n",
    "both_ypred = both.predict(np.hstack((X,coordinates))[test,:])\n",
    "\n",
    "(skm.explained_variance_score(y[test,], sp_ypred),\n",
    "\n",
    "skm.explained_variance_score(y[test,],att_ypred),\n",
    "\n",
    "skm.explained_variance_score(y[test,], both_ypred))\n",
    "\n",
    "result->> (0.1443088606590084, 0.3149860849884514, -5.684468673550214e-09)ApplicationNow we are going to use GeoPandas to visualize data comprising of road accidents in Auckland. Location of data is stored in the local variable path.\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "roads = gpd.read_file(str(path))\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "\n",
    "ax = roads.plot(column=’type’, ax=ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "Above we have obtained the road map of Auckland. To help the viewers draw better insights from the plot, we can scatter plot the accident locations on it.Dataset comprising of road  accidents is   stored in local variabel  path1.\n",
    "\n",
    "crashes = pd.read_csv(path1)\n",
    "\n",
    "f = crashes.copy()\n",
    "\n",
    "cond = f[‘LG_REGION_DESC’].str.contains(‘Auckland’)\n",
    "\n",
    "cond &= (f[‘EASTING’] > 0) & (f[‘NORTHING’] > 0)\n",
    "\n",
    "f = f[cond].copy()\n",
    "\n",
    "crashes = gpd.GeoDataFrame(f, crs=NZTM, geometry=geometry)\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "\n",
    "base = roads.plot(color=’black’, ax=ax)\n",
    "\n",
    "crashes.plot(ax=base, marker=’o’, color=’red’, markersize=3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "We have discussed only a few application ofGeoPandas in this article. It can also be used in combination with other packages like shapely, fiona and plotly for advanced data visualization. The key to data visualization is to know at what circumstances or conditions a specific package is suited.\n",
    "\n",
    "When should we use GeoPandas?\n",
    "\n",
    "    For exploratory data analysis, including in Jupyter notebooks.\n",
    "    For highly compact and readable code. Which in turn improves reproducibility.\n",
    "    If we are comfortable with Pandas, R dataframes, or tabular/relational approaches.\n",
    "\n",
    "When it may not be the best tool?\n",
    "\n",
    "    For polished map creation and multi-layer, interactive visualization; if we are comfortable with GIS software, one option is to use a desktop GIS like QGIS. We can generate intermediate GIS files and plots with GeoPandas, then shift over to QGIS. Or refine the plots in Python with matplotlib or additional packages. GeoPandas can help us manage and pre-process the data, and do initial visualizations.\n",
    "    If we need very high performance. Performance has been increasing and substantial enhancements are in the works (including possibly a parallelization implementation).\n",
    "\n",
    "Advantages of using plotly:\n",
    "\n",
    "1.We can create interactive plots with plotly which help us to draw better insights from the given data.\n",
    "\n",
    "2. After we learn the basic idea of the library, it allows us to rapidly build stunning visualizations.\n",
    "\n",
    "3.Once we get accustomed to the basics of the library, it is very user friendly in nature.\n",
    "\n",
    "4.Plotly uses declarative programming, which means less effort spent building up a figure, allowing us to focus on what to present and how to interpret it.\n",
    "\n",
    "In this article, we explored some features and applications of GeoPandas. To explore more properties of this amazing python package, we can visit-: http://geopandas.org\n",
    "“Introduction to Geospatial Data Analysis with Python\n",
    "\n",
    "” is also a great visual reference material to start with-:\n",
    "\n",
    "https://www.youtube.com/watch?v=kJXUUO5M4ok\n",
    "\n",
    "References:\n",
    "\n",
    "Following tutorial is a great example driven approach to get started with GeoPandas:\n",
    "\n",
    "https://github.com/mrcagney/introducing_geopandas\n",
    "\n",
    "To explore more properties of Plotly, we can visit-: https://plot.ly/python\n",
    "\n",
    "    Data Science\n",
    "    Data Visualization\n",
    "    Data Analysis\n",
    "    Visualization Tool\n",
    "    Analysis\n",
    "\n",
    "More from Sukant Khurana\n",
    "\n",
    "Emerging tech, edtech, AI, neuroscience, drug-discovery, design-thinking, sustainable development, art, & literature. There is only one life, use it well.\n",
    "More From Medium\n",
    "Scaling Quality Training Data: Best Practices for Your Data Production Line\n",
    "CloudFactory\n",
    "Health Data Science FAQ Series| 002 — Technology Tools Part 1\n",
    "Dalton Fabian in The Data Science Pharmacist\n",
    "Here’s what Airbnb data tells us about the past year\n",
    "Amber Standish\n",
    "Let’s make a bet; Leafs win the Stanley Cup?\n",
    "Patrick Chong\n",
    "Spatial Data to Enhance The Logistic Distribution for Victims in Palu Earthquake\n",
    "Sry Handini Puteri\n",
    "Welcome To Patchwords\n",
    "Sally\n",
    "Mercari Price Suggestion Challenge: A Machine Learning Case Study\n",
    "Pratikpophali\n",
    "🤹‍♀️ Does Skill Sharing Influence Communication?\n",
    "Alessandro Marchesin\n",
    "\n",
    "About\n",
    "\n",
    "Write\n",
    "\n",
    "Help\n",
    "\n",
    "Legal\n",
    "\n",
    "Get the Medium app\n",
    "A button that says 'Download on the App Store', and if clicked it will lead you to the iOS App store\n",
    "A button that says 'Get it on, Google Play', and if clicked it will lead you to the Google Play store\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59dedc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b2831d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
